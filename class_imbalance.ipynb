{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fastkde import fastkde\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code should not be run again. It was used to subset the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>527987</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47519</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>938513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232653</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59516</th>\n",
       "      <td>1207113</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59517</th>\n",
       "      <td>1212728</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59518</th>\n",
       "      <td>757821</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59519</th>\n",
       "      <td>875118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59520</th>\n",
       "      <td>776400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59521 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0       527987       0          2              1          8              0   \n",
       "1        47519       0          3              1          3              0   \n",
       "2       938513       0          1              1          1              0   \n",
       "3       279774       0          0              1          2              0   \n",
       "4       232653       0          3              1          2              1   \n",
       "...        ...     ...        ...            ...        ...            ...   \n",
       "59516  1207113       1          1              1          7              0   \n",
       "59517  1212728       1          0              1          5              0   \n",
       "59518   757821       1          3              1          7              0   \n",
       "59519   875118       1          0              3          5              1   \n",
       "59520   776400       1          0              3          4              1   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0                  0              0              0              0  ...   \n",
       "1                  0              1              0              0  ...   \n",
       "2                  0              1              0              0  ...   \n",
       "3                  0              1              0              0  ...   \n",
       "4                  0              0              1              0  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "59516              4              0              0              1  ...   \n",
       "59517              0              0              1              0  ...   \n",
       "59518              1              1              0              0  ...   \n",
       "59519              0              0              1              0  ...   \n",
       "59520              0              0              0              1  ...   \n",
       "\n",
       "       ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0               3           1           1           7               1   \n",
       "1               3           2           3           5               0   \n",
       "2               1           1           1           4               0   \n",
       "3               6           0           5           3               0   \n",
       "4               4           0           5          11               0   \n",
       "...           ...         ...         ...         ...             ...   \n",
       "59516           3           1           1           9               0   \n",
       "59517           6           2           1           2               0   \n",
       "59518           3           1           3           8               0   \n",
       "59519           7           2           4           6               0   \n",
       "59520           6           1           1           6               0   \n",
       "\n",
       "       ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0                   1               0               1               0   \n",
       "1                   0               1               1               1   \n",
       "2                   1               1               0               0   \n",
       "3                   1               1               0               0   \n",
       "4                   1               0               1               1   \n",
       "...               ...             ...             ...             ...   \n",
       "59516               0               1               0               1   \n",
       "59517               1               1               0               0   \n",
       "59518               0               0               1               0   \n",
       "59519               1               1               0               0   \n",
       "59520               1               0               0               1   \n",
       "\n",
       "       ps_calc_20_bin  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "59516               0  \n",
       "59517               0  \n",
       "59518               0  \n",
       "59519               0  \n",
       "59520               0  \n",
       "\n",
       "[59521 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing train data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##subsetting the train data to only be 10% of each class and saving it over the original data\n",
    "#subset_train = train.groupby('target').sample(frac=0.1)\n",
    "#subset_train['target'].value_counts()\n",
    "#subset_train.to_csv('data/train.csv', index=False)\n",
    "#subset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up\n",
    "Loading data, setting X and y, and defining a cross validation function that can be used for all methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', header = 0)\n",
    "\n",
    "x = train.drop(columns=['target', 'id'])\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(kf, x, y, model):\n",
    "    cm_list = []\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(x, y):\n",
    "        xtrain, xtest = x[train_index], x[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        model.fit(xtrain, ytrain)\n",
    "        y_pred = model.predict(xtest)\n",
    "        accuracy.append(accuracy_score(ytest, y_pred))\n",
    "        recall.append(recall_score(ytest, y_pred, average = 'binary'))\n",
    "        cm_list.append(confusion_matrix(ytest, y_pred))\n",
    "    return cm_list, accuracy, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_sampled, y_sampled = oversample.fit_resample(x, y)\n",
    "counter = Counter(y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "scaler = StandardScaler()\n",
    "x_sampled = scaler.fit_transform(x_sampled)\n",
    "results, accuracy, recall = crossvalidate(kf, x_sampled, y_sampled, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8852709123403514,\n",
       "  0.8911555729915871,\n",
       "  0.8881042674687242,\n",
       "  0.8934658471731833,\n",
       "  0.8900610287707061],\n",
       " [np.float64(0.997384481255449),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.9999128236422282),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0)],\n",
       " [array([[ 8869,  2602],\n",
       "         [   30, 11440]]),\n",
       "  array([[ 8974,  2497],\n",
       "         [    0, 11470]]),\n",
       "  array([[ 8904,  2566],\n",
       "         [    1, 11470]]),\n",
       "  array([[ 9026,  2444],\n",
       "         [    0, 11471]]),\n",
       "  array([[ 8948,  2522],\n",
       "         [    0, 11470]])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, recall, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN with FastKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  0.9808586369029308\n",
      "Average Recall:  0.9614056424597661\n",
      "Confusion Matrix (average across folds):\n",
      " [[11470.4     0. ]\n",
      " [  435.6 10851. ]]\n"
     ]
    }
   ],
   "source": [
    "# converting X and y to numpy arrays\n",
    "X = np.array(x) \n",
    "y = np.array(y) \n",
    "\n",
    "# applying FastKDE to the feature data to smooth and estimate the density\n",
    "num_points = 257  # setting number of points for KDE\n",
    "var_names = [f'feature_{i}' for i in range(X.shape[1])]  # assigning names to each feature\n",
    "\n",
    "# calculating the pdf for each feature in the data, the density estimation for each feature is stored in kde_result\n",
    "kde_result = {}\n",
    "for i in range(X.shape[1]):\n",
    "    kde_result[f'feature_{i}'] = fastkde.pdf(X[:, i], var_names=[var_names[i]], num_points=num_points)\n",
    "\n",
    "# using ADASYN to generate synthetic data to balance the data\n",
    "adasyn = ADASYN(sampling_strategy='minority', n_neighbors=5)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
    "\n",
    "# splitting the resampled data using stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# creating the RandomForest model\n",
    "model = RandomForestClassifier()  # performs better than KNN\n",
    "\n",
    "# calling the crossvalidate function with the resampled data\n",
    "cm_list, accuracy, recall = crossvalidate(skf, X_resampled, y_resampled, model)\n",
    "\n",
    "# printing average scores across all folds\n",
    "print(\"Average Accuracy: \", np.mean(accuracy))\n",
    "print(\"Average Recall: \", np.mean(recall))\n",
    "print(\"Confusion Matrix (average across folds):\\n\", np.mean(cm_list, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nflows\n",
      "  Downloading nflows-0.14.tar.gz (45 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (1.21.5)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: torch in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (2.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (4.64.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->nflows) (1.16.0)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.67.1-cp39-cp39-win_amd64.whl (4.4 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (3.3.4)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-5.28.3-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (61.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (2.0.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2024.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from jinja2->torch->nflows) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from sympy->torch->nflows) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tqdm->nflows) (0.4.6)\n",
      "Building wheels for collected packages: nflows\n",
      "  Building wheel for nflows (setup.py): started\n",
      "  Building wheel for nflows (setup.py): finished with status 'done'\n",
      "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53670 sha256=d393ae74ceb06b9755084afd78db497a74ead20727776c61fa3168ccd38cf608\n",
      "  Stored in directory: c:\\users\\romer\\appdata\\local\\pip\\cache\\wheels\\3b\\88\\52\\cbd4ed0597b48916de3de19b28d7297c72595f56085068c772\n",
      "Successfully built nflows\n",
      "Installing collected packages: tensorboard-data-server, protobuf, grpcio, absl-py, tensorboard, nflows\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.67.1 nflows-0.14 protobuf-5.28.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install nflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "from nflows import transforms, flows\n",
    "\n",
    "def generate_synthetic_minority_samples(minority_class_data, majority_class_data, imbalance_ratio=1.0, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Generates synthetic samples for a minority class using a simple normalizing flow.\n",
    "    \n",
    "    Parameters:\n",
    "    - minority_class_data (Tensor): Tensor containing data for the minority class.\n",
    "    - majority_class_data (Tensor): Tensor containing data for the majority class.\n",
    "    - imbalance_ratio (float): Desired ratio of minority to majority class after resampling.\n",
    "    - num_epochs (int): Number of training epochs for the normalizing flow.\n",
    "    - lr (float): Learning rate for training the normalizing flow.\n",
    "\n",
    "    Returns:\n",
    "    - balanced_data (Tensor): Combined tensor of original and synthetic data to address class imbalance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dimensionality of the data (assuming minority_class_data is 2D tensor [samples, features])\n",
    "    dim = minority_class_data.shape[1]\n",
    "    \n",
    "    # 1. Define a simple normalizing flow model (using MaskedAffineAutoregressiveTransform)\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.MaskedAffineAutoregressiveTransform(features=dim, hidden_features=dim * 2)\n",
    "    ])\n",
    "    base_distribution = dist.Normal(torch.zeros(dim), torch.ones(dim))\n",
    "    flow_model = flows.Flow(transform, base_distribution)\n",
    "\n",
    "    # 2. Train the flow model on the minority class data\n",
    "    optimizer = torch.optim.Adam(flow_model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate log probability (negative log likelihood)\n",
    "        loss = -flow_model.log_prob(minority_class_data).mean()  # No context, just the data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    # 3. Generate synthetic data samples\n",
    "    num_samples = int(len(majority_class_data) * imbalance_ratio) - len(minority_class_data)\n",
    "    synthetic_samples = flow_model.sample(num_samples)\n",
    "\n",
    "    # 4. Combine the original majority class data with the synthetic minority class data\n",
    "    balanced_data = torch.cat([majority_class_data, minority_class_data, synthetic_samples], dim=0)\n",
    "    return balanced_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate dummy minority and majority class data\n",
    "    minority_class_data = torch.randn(50, 2)  # 50 samples, 2 features\n",
    "    majority_class_data = torch.randn(150, 2)  # 150 samples, 2 features\n",
    "\n",
    "    # Generate synthetic data to balance the dataset\n",
    "    balanced_data = generate_synthetic_minority_samples(minority_class_data, majority_class_data, imbalance_ratio=2.0)\n",
    "\n",
    "    print(f\"Original majority class data: {majority_class_data.shape}\")\n",
    "    print(f\"Original minority class data: {minority_class_data.shape}\")\n",
    "    print(f\"Balanced data: {balanced_data.shape}\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_prob() got an unexpected keyword argument 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m balanced \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_synthetic_minority_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mgenerate_synthetic_minority_samples\u001b[1;34m(minority_class_data, majority_class_data, imbalance_ratio, num_epochs, lr)\u001b[0m\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Pass context data to log_prob\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminority_class_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# Ensure context is passed correctly\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\romer\\anaconda3\\lib\\site-packages\\nflows\\distributions\\base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\romer\\anaconda3\\lib\\site-packages\\nflows\\flows\\base.py:40\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     38\u001b[0m embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m     39\u001b[0m noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inputs, context\u001b[38;5;241m=\u001b[39membedded_context)\n\u001b[1;32m---> 40\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob \u001b[38;5;241m+\u001b[39m logabsdet\n",
      "\u001b[1;31mTypeError\u001b[0m: log_prob() got an unexpected keyword argument 'context'"
     ]
    }
   ],
   "source": [
    "balanced = generate_synthetic_minority_samples(torch.tensor(train[train['target'] == 1].values, dtype = torch.float32),\n",
    "                                               torch.tensor(train[train['target'] == 0].values, dtype = torch.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
