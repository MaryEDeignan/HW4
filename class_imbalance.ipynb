{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', header = 0)\n",
    "\n",
    "x = train.drop(columns=['target', 'id'])\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(kf, x, y, model):\n",
    "    cm_list = []\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(x, y):\n",
    "        xtrain, xtest = x[train_index], x[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        model.fit(xtrain, ytrain)\n",
    "        y_pred = model.predict(xtest)\n",
    "        accuracy.append(accuracy_score(ytest, y_pred))\n",
    "        recall.append(recall_score(ytest, y_pred, average = 'binary'))\n",
    "        cm_list.append(confusion_matrix(ytest, y_pred))\n",
    "    return cm_list, accuracy, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_sampled, y_sampled = oversample.fit_resample(x, y)\n",
    "counter = Counter(y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "scaler = StandardScaler()\n",
    "x_sampled = scaler.fit_transform(x_sampled)\n",
    "results, accuracy, recall = crossvalidate(kf, x_sampled, y_sampled, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8382372172093632,\n",
       "  0.8415936532845124,\n",
       "  0.84120134257443,\n",
       "  0.8393705592607122,\n",
       "  0.8403661726242372],\n",
       " [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [array([[ 7760,  3711],\n",
       "         [    0, 11470]], dtype=int64),\n",
       "  array([[ 7837,  3634],\n",
       "         [    0, 11470]], dtype=int64),\n",
       "  array([[ 7827,  3643],\n",
       "         [    0, 11471]], dtype=int64),\n",
       "  array([[ 7785,  3685],\n",
       "         [    0, 11471]], dtype=int64),\n",
       "  array([[ 7808,  3662],\n",
       "         [    0, 11470]], dtype=int64)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, recall, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN with FastKDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nflows\n",
      "  Downloading nflows-0.14.tar.gz (45 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (1.21.5)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: torch in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (2.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\romer\\anaconda3\\lib\\site-packages (from nflows) (4.64.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from matplotlib->nflows) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->nflows) (1.16.0)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.67.1-cp39-cp39-win_amd64.whl (4.4 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (3.3.4)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-5.28.3-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (61.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tensorboard->nflows) (2.0.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2024.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch->nflows) (2.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from jinja2->torch->nflows) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from sympy->torch->nflows) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\romer\\anaconda3\\lib\\site-packages (from tqdm->nflows) (0.4.6)\n",
      "Building wheels for collected packages: nflows\n",
      "  Building wheel for nflows (setup.py): started\n",
      "  Building wheel for nflows (setup.py): finished with status 'done'\n",
      "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53670 sha256=d393ae74ceb06b9755084afd78db497a74ead20727776c61fa3168ccd38cf608\n",
      "  Stored in directory: c:\\users\\romer\\appdata\\local\\pip\\cache\\wheels\\3b\\88\\52\\cbd4ed0597b48916de3de19b28d7297c72595f56085068c772\n",
      "Successfully built nflows\n",
      "Installing collected packages: tensorboard-data-server, protobuf, grpcio, absl-py, tensorboard, nflows\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.67.1 nflows-0.14 protobuf-5.28.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install nflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "from nflows import transforms, flows\n",
    "\n",
    "def generate_synthetic_minority_samples(minority_class_data, majority_class_data, imbalance_ratio=1.0, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Generates synthetic samples for a minority class using a simple normalizing flow.\n",
    "    \n",
    "    Parameters:\n",
    "    - minority_class_data (Tensor): Tensor containing data for the minority class.\n",
    "    - majority_class_data (Tensor): Tensor containing data for the majority class.\n",
    "    - imbalance_ratio (float): Desired ratio of minority to majority class after resampling.\n",
    "    - num_epochs (int): Number of training epochs for the normalizing flow.\n",
    "    - lr (float): Learning rate for training the normalizing flow.\n",
    "\n",
    "    Returns:\n",
    "    - balanced_data (Tensor): Combined tensor of original and synthetic data to address class imbalance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dimensionality of the data (assuming minority_class_data is 2D tensor [samples, features])\n",
    "    dim = minority_class_data.shape[1]\n",
    "    \n",
    "    # 1. Define a simple normalizing flow model (using MaskedAffineAutoregressiveTransform)\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.MaskedAffineAutoregressiveTransform(features=dim, hidden_features=dim * 2)\n",
    "    ])\n",
    "    base_distribution = dist.Normal(torch.zeros(dim), torch.ones(dim))\n",
    "    flow_model = flows.Flow(transform, base_distribution)\n",
    "\n",
    "    # 2. Train the flow model on the minority class data\n",
    "    optimizer = torch.optim.Adam(flow_model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate log probability (negative log likelihood)\n",
    "        loss = -flow_model.log_prob(minority_class_data).mean()  # No context, just the data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    # 3. Generate synthetic data samples\n",
    "    num_samples = int(len(majority_class_data) * imbalance_ratio) - len(minority_class_data)\n",
    "    synthetic_samples = flow_model.sample(num_samples)\n",
    "\n",
    "    # 4. Combine the original majority class data with the synthetic minority class data\n",
    "    balanced_data = torch.cat([majority_class_data, minority_class_data, synthetic_samples], dim=0)\n",
    "    return balanced_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate dummy minority and majority class data\n",
    "    minority_class_data = torch.randn(50, 2)  # 50 samples, 2 features\n",
    "    majority_class_data = torch.randn(150, 2)  # 150 samples, 2 features\n",
    "\n",
    "    # Generate synthetic data to balance the dataset\n",
    "    balanced_data = generate_synthetic_minority_samples(minority_class_data, majority_class_data, imbalance_ratio=2.0)\n",
    "\n",
    "    print(f\"Original majority class data: {majority_class_data.shape}\")\n",
    "    print(f\"Original minority class data: {minority_class_data.shape}\")\n",
    "    print(f\"Balanced data: {balanced_data.shape}\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_prob() got an unexpected keyword argument 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m balanced \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_synthetic_minority_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mgenerate_synthetic_minority_samples\u001b[1;34m(minority_class_data, majority_class_data, imbalance_ratio, num_epochs, lr)\u001b[0m\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Pass context data to log_prob\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminority_class_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# Ensure context is passed correctly\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\romer\\anaconda3\\lib\\site-packages\\nflows\\distributions\\base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\romer\\anaconda3\\lib\\site-packages\\nflows\\flows\\base.py:40\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[1;34m(self, inputs, context)\u001b[0m\n\u001b[0;32m     38\u001b[0m embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m     39\u001b[0m noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inputs, context\u001b[38;5;241m=\u001b[39membedded_context)\n\u001b[1;32m---> 40\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob \u001b[38;5;241m+\u001b[39m logabsdet\n",
      "\u001b[1;31mTypeError\u001b[0m: log_prob() got an unexpected keyword argument 'context'"
     ]
    }
   ],
   "source": [
    "balanced = generate_synthetic_minority_samples(torch.tensor(train[train['target'] == 1].values, dtype = torch.float32),\n",
    "                                               torch.tensor(train[train['target'] == 0].values, dtype = torch.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
